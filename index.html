---
title: 'Problem Set 1'
author: Sumeet Sharma
date: 'Due: Monday, October 19, 2015'
output: html_document
---

<!-- This syntax can be used to add comments that are ignored during knitting process. -->

<!-- List all collaborators here. -->
##### Collaborators: 

\ <!-- This is an example of how to add vertical space to your document. -->


### Problem Set 1: Data Extraction and Manipulation ###


\  

##### Instructions: #####
<hr> <!-- A horizontal line -->

Before beginning this assignment, please ensure you have access to R and RStudio. 

1. Download the `problemset1.Rmd` file from Canvas. Open `problemset1.Rmd` in RStudio and supply your solutions to the assignment by editing `problemset1.Rmd`. 

2. Replace the "Insert Your Name Here" text in the `author:` field with your own full name. Any collaborators must be listed on the top of your assignment. 

3. Be sure to include well-documented (e.g. commented) code chucks, figures and clearly written text chunk explanations as necessary. Any figures should be clearly labeled and appropriately referenced within the text. 

4. You can assume that all packages listed in the first code chunk will be installed. Please be sure to **explicitly** note if additional packages are necessary; if additional packages are used you run the risk of the grader not being able to knit your assignment correctly.

5. When you have completed the assignment and have **checked** that your code both runs in the Console and knits correctly when you click `Knit HTML`, rename the R Markdown file to `problemset1_YourLastName_YourFirstName.Rmd`, and submit on Canvas.


```{r Setup, message=FALSE}
# Stardard libraries
library(jsonlite)
library(dplyr)
library(ggplot2)
library(tidyr)
library(RSocrata)
library(acs)
```

<hr>

\ 


#### Problem 1: Open Government Data ####

Use the following code to obtain data on the Seattle Police Department Police Report Incidents.

```{r}
policeIncidents <- fromJSON("https://data.seattle.gov/resource/7ais-f98f.json")
```

##### (a) Describe, in detail, what the data represents.

The dataset represents the incident reports recorded by Seattle Police
department officers for incidents occurred around Seattle. The report includes 
information such as type of the offense, summary of the offense, occurred date,
location, locality name, and other general information about the incident for
record maintenance purposes. 

```{r}
dim(policeIncidents) # get dimensions of the dataset
head(policeIncidents) # view top few records from the data
colnames(policeIncidents) # get the column names for the variables

```


##### (b) Describe each variable and what it measures. Be sure to note when data is missing. Confirm that each variable is appropriately cast - it has the correct data type. If any are incorrect, recast them to be in the appropriate format. 

There are 19 variables in the dataset.

offense_code:It is a categorical variable which measures the different types of offense code.

Offense_type: It records the description of different types of offense. Every
offense type has its own offense_code 

census_tract_2000: It captures the geographic region (defined for the purpose
of taking a census) where the incident happened.

date_reported: It captures the date and time when the incident was reported to police

location: It measures the GPS coordinates latitude and longitude of the location
of the incident.

zone_beat: It captures the information/code about thezones as designated 
by Seattle police department.

offense_code_extension: It is a numeric code type for the offenses.

district_sector: It contains the code for different district or sectors on which
police department has divided Seattle area. These are generally the first 
character of zone_beat value.

hundred_block_location: It captures the address of the area where the incident
occurred

summarized_offense_description: It records the summary of the offense
month: It records the month when the incident was occurred

general_offense_number: It records the unique offense number for the incident

year: It recrods the year of the incident when it occurred

longtiude: It captures the longtiude coordinates where the incident happened

summary_offense_code: It records the code for the summary of the offense type

latitude: It captures the latitude coordinates where the incident happened

rms_cdw_id: It measures the unique id of the record in the dataset

occurred_date_or_date_range_start: It captures the the date and time when the 
incident was occurred.

occurred_date_range_end: It captures the the date and time when the 
incident was ended.


```{r}
colnames(policeIncidents) # get the column names for the variables
class(policeIncidents) # get the data type for policeIncidents
head(policeIncidents) # view top few records from the data
summary(policeIncidents) # get summary of the data
# All the variables have character data type
# Set correct data types for the following variables

# Set offense_code to numeric
policeIncidents$offense_code <- as.numeric(policeIncidents$offense_code)
# Set offense_code_extension to numeric
policeIncidents$offense_code_extension <- as.numeric(policeIncidents$offense_code_extension)
# Set general_offense_number to numeric
policeIncidents$general_offense_number <- as.numeric(policeIncidents$general_offense_number)
# Set month to numeric
policeIncidents$month <- as.numeric(policeIncidents$month)
# Set year to numeric
policeIncidents$year <- as.numeric(policeIncidents$year)
# Set latitude and longitude to numeric
policeIncidents$latitude <- as.numeric(policeIncidents$latitude)
policeIncidents$longitude <- as.numeric(policeIncidents$longitude)
# Get data type for all the columns/variables
sapply(policeIncidents, class) 

```



##### (c) Produce a clean dataset, according to the rules of tidy data discussed in class. Export the data for future analysis using the Rdata format. 

After changing data type for offense_code, NAs are introduced by coercion
wherever there were missing records for offense_code, marked by 'X' in the data

For any future analysis, these missing records will not fit in any category for
offense type. To make our data tidy, we can remove these records.

```{r}
# Evaluate for any NAs in offense_code
any(is.na(policeIncidents$offense_code))
# Count for records with NA value in offense_code
sum(is.na(policeIncidents$offense_code))

# Remove observations with NA in offense_code variable
incidents.tidy <- policeIncidents[!(is.na(policeIncidents$offense_code)), ]
dim(incidents.tidy)
# Save the clean dataset for future analysis
save(incidents.tidy, file= 'incidents.Rdata')
```

After removing 111 records with NA values in offense_code, we are left with 889
observations and a clean dataset.

##### (d) Describe any concerns you might have about this data. This may include biases, missing data, or ethical concerns.

There are some records with same general_offense_number but with unique
rms_cdw_id. All these records have similar values for all the variables. This 
might bring bias in the data by inlcuding the same information multiple times.
The same incident with multiple general_offense_number but with unique rms_cdw_id will result in taking into account the same incident multiple times. This can
affect our analysis due to duplicate records and repeated values in the 
variables. 

I see one ethical concern with the availability of location data. Anyone with
access to right tools can figure out the crime areas with most burglary or other
common offense type. Somone with malcious intent can plan an attack in those
areas by seeing crime patterns in those areas and see how people report different crimes to police.


#### Problem 2:  Exploring the NYC Flights Data ####

In this problem set we will use the data on all flights that departed NYC (i.e. JFK, LGA or EWR) in 2013. You can find this data in the `nycflights13` R package. 

##### (a) Importing Data: ##### 
Load the data and describe in a short paragraph how the data was collected and what each variable represents. 

First, I installed the package 'nycflights13' using install.packages() and then 
attached the library 'nycflights13' using library(). This package contains 
information about all flights that departed from NYC (i.e., EWR, JFK and LGA) in 2013: 336,776 flights with 16 variables.

'nycflights13' packages contains the following datasets:
airlines            Airline names.
airports            Airport metadata
flights             Flights data
planes              Plane metadata.
weather             Hourly weather data

I attached the required library using library() function. After that, one can
view different datasets inside the package by calling datasets using available R
functions. To read datasets properly, I used tbl_df() function to view the 
flights dataset. The main advantage to using a tbl_df over a regular data 
frame is the printing: tbl objects only print a few rows and all the columns 
that fit on one screen, providing describing the rest of it as text.

There are 16 variables in 'flights' dataset. These are:

year: contains year in yyyy format

month: contains month in m format

day: contains day in d format

dep_time: contains departure time of the flight

dep_delay: contains delay time at the time of departure

arr_time: contains arrival time of the flight

arr_delay: contains delay time at the time of arrival

carrier: contains the 2 digit string of the airline carrier

tailnum: contains the aircraft registration number in alphanumeric

flight: contains the flight number in numeric

origin: Origin city of the flight

dest: destination city of the flight

air_time: Total duration of the flight

distance: Total distance of the flight

hour: contains the departure hour of the flight

minute: it contains the departure minute of the flight

```{r}
# Attach nycflights13 library
library(nycflights13)
# check dimensions of the flights dataset
dim(flights)
# Convert to an easy readable format using tbl_df()
flights <- tbl_df(flights)
head(flights)
colnames(flights)
class(flights)

```


##### (b) Data Manipulation: ##### 
Use the flights data to answer each of the following questions. Be sure to answer each question with a written response and supporting analysis.

- How many flights were there from NYC airports to Seattle in 2013?
```{r}
# use dplyr library 
# first filter flights using filter()with destination 
# airport equals to SEATTLE (SEA). Then, use summarise() function to count the
# rows using n()
flights %>%
        filter(dest == 'SEA') %>%
        summarise(flights_to_SEA = n())

```

There are 3923 flights from NYC airports to Seattle in 2013. 

- How many airlines fly from NYC to Seattle?
```{r}
# Use fliter() to filter flights to destination equals to SEATTLE (SEA)
# Find unique airlines by using distinct() function on variable 'carrier'
# Select carrier variable to display the results and sort using arrange()
flights %>%
        filter(dest == 'SEA') %>%
        distinct(carrier) %>%
        select(carrier) %>%
        arrange(carrier)
```

There are 5 different airlines which fly from NYC to Seattle

- How many unique air planes fly from NYC to Seattle?
```{r}
# Subset dataset for flights to destination SEATTLE (SEA)
flightSeattle <- flights[flights$dest == 'SEA', ]
# Count the number of unique tailnum in flightSeattle dataset
count <- length(unique(flightSeattle$tailnum))
# Print the count
count
```

There are 936 unqiue air planes fly from NYC to Seattle

- What is the average arrival delay for flights from NYC to Seattle?
```{r}
# Filter flights to destination SEATTLE(SEA) using filter()
# Calculate the mean on arr_delay using mean() with no NA values and use
# summarise() to get the results

flights %>%
        filter(dest == 'SEA') %>%
        summarise(avg = mean(arr_delay, na.rm = TRUE))
```

The average arrival delay fo flights from NYC to Seattle is -1.099099

- What proportion of flights to Seattle come from each NYC airport?

```{r}
# Filter flights to destination SEATTLE(SEA) using filter()
# group all the flights with origin airport code using group_by()
# get the count for each origin airport using n() and summarise()
# calculate the proportion and add a new variable using mutate()

flights %>%
        filter(dest == 'SEA') %>%
        group_by(origin) %>%
        summarise(num = n()) %>%
        mutate(prop = num / sum(num))

```
